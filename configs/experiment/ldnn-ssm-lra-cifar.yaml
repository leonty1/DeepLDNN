# @package _global_
defaults:
  - /pipeline: cifar
  - /model: ldnn-ssm
  - override /scheduler: cosine_warmup

model:
  dropout: 0.1
  n_layers: 6
  prenorm: false
  d_model: 256
  norm: batch
  residual: R
  layer:
    head: 64
    bidirectional: true
    channel: 1
    conj_sym: true
    keep_d_state: true
    discrete_method: zoh
    d_s: 512
    Lambda_init: hippo
    B_init: hippo
    C_init: trunc_normal
    D_init: one
    t_init: uniform
    dt_min: 0.001
    dt_max: 0.1
    d_dt_is_n: true
    version_A_neg: clip
    version_A_imag: same
    version_B_imag: zero
    version_C_imag: zero
    max_kernel_length:
    D_value: 1
    trainable:
      log_dt: true
      Lambda: true
      B: true
      C: true
      D: true
    lr:
      log_dt: 0.001
      Lambda: 0.001
      B: 0.005
      C: 0.005
      D: 0.001
    activation:
    acttivation_post: half_glu1

dataset:
  grayscale: true
  augment: true

decoder:
  mode: pool

loader:
  batch_size: 100

optimizer:
  lr: 0.005


scheduler:
  num_training_steps: 100000

trainer:
  max_epochs: 200

train:
  seed: 110
